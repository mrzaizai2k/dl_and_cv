{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed046b99",
   "metadata": {},
   "source": [
    "Transfer Learning for Computer Vision Tutorial\n",
    "==============================================\n",
    "\n",
    "**Author**: [Sasank Chilamkurthy](https://chsasank.github.io)\n",
    "\n",
    "In this tutorial, you will learn how to train a convolutional neural\n",
    "network for image classification using transfer learning. You can read\n",
    "more about the transfer learning at [cs231n\n",
    "notes](https://cs231n.github.io/transfer-learning/)\n",
    "\n",
    "Quoting these notes,\n",
    "\n",
    "> In practice, very few people train an entire Convolutional Network\n",
    "> from scratch (with random initialization), because it is relatively\n",
    "> rare to have a dataset of sufficient size. Instead, it is common to\n",
    "> pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
    "> contains 1.2 million images with 1000 categories), and then use the\n",
    "> ConvNet either as an initialization or a fixed feature extractor for\n",
    "> the task of interest.\n",
    "\n",
    "These two major transfer learning scenarios look as follows:\n",
    "\n",
    "-   **Finetuning the ConvNet**: Instead of random initialization, we\n",
    "    initialize the network with a pretrained network, like the one that\n",
    "    is trained on imagenet 1000 dataset. Rest of the training looks as\n",
    "    usual.\n",
    "-   **ConvNet as fixed feature extractor**: Here, we will freeze the\n",
    "    weights for all of the network except that of the final fully\n",
    "    connected layer. This last fully connected layer is replaced with a\n",
    "    new one with random weights and only this layer is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba43dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from tempfile import TemporaryDirectory\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR, OneCycleLR\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803c156",
   "metadata": {},
   "source": [
    "Load Data\n",
    "=========\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "The problem we\\'re going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants\n",
    "and bees. There are 75 validation images for each class. Usually, this\n",
    "is a very small dataset to generalize upon, if trained from scratch.\n",
    "Since we are using transfer learning, we should be able to generalize\n",
    "reasonably well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 200\n",
    "lr= 1e-3  # higher lr for classifier\n",
    "momentum = 0.9\n",
    "step_size = 7 \n",
    "gamma = 0.1\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "patience = 20\n",
    "label_smoothing = 0.05\n",
    "warmup_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a64ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Load the .npy dataset\n",
    "# path_to_fer = 'fer13_v2.npy'\n",
    "# m = np.load(path_to_fer, allow_pickle=True).item()\n",
    "# x_train, y_train = m['train']\n",
    "# x_val, y_val = m['val']\n",
    "# x_test, y_test = m['test']\n",
    "\n",
    "# # Define custom dataset class\n",
    "# class FERDataset(Dataset):\n",
    "#     def __init__(self, images, labels, transform=None):\n",
    "#         self.images = images\n",
    "#         self.labels = labels\n",
    "#         self.transform = transform\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.images)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.images[idx].astype(np.uint8)\n",
    "#         label = int(self.labels[idx])  # Ensure label is an integer\n",
    "#         return self.transform(image), label\n",
    "\n",
    "# # Define transformations\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((224, 224)),  # Resize from 48x48 to 224x224\n",
    "#         transforms.Grayscale(num_output_channels=3),  # Convert 1-channel to 3-channel\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5], [0.5])  # Normalize for grayscale\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((224, 224)),  # Resize from 48x48 to 224x224\n",
    "#         transforms.Grayscale(num_output_channels=3),  # Convert 1-channel to 3-channel\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5], [0.5])  # Normalize for grayscale\n",
    "#     ]),\n",
    "# }\n",
    "\n",
    "# # Create datasets\n",
    "# datasets = {\n",
    "#     'train': FERDataset(x_train, y_train, transform=data_transforms['train']),\n",
    "#     'val': FERDataset(x_val, y_val, transform=data_transforms['val']),\n",
    "#     'test': FERDataset(x_test, y_test, transform=data_transforms['val'])\n",
    "# }\n",
    "\n",
    "# # Create dataloaders\n",
    "# dataloaders = {\n",
    "#     x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#     for x in ['train', 'val', 'test']\n",
    "# }\n",
    "\n",
    "# dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "# # Get the number of unique classes in the dataset\n",
    "# num_classes = len(np.unique(np.concatenate([y_train, y_val, y_test])))\n",
    "\n",
    "# print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "\n",
    "# # Select device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa95ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npy dataset\n",
    "path_to_fer = 'fer13_v2.npy'\n",
    "m = np.load(path_to_fer, allow_pickle=True).item()\n",
    "x_train, y_train = m['train']\n",
    "x_val, y_val = m['val']\n",
    "x_test, y_test = m['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0bc21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of samples per class for each dataset\n",
    "train_counts = Counter(y_train)\n",
    "val_counts = Counter(y_val)\n",
    "test_counts = Counter(y_test)\n",
    "\n",
    "# Get sorted class labels\n",
    "class_labels = sorted(set(y_train) | set(y_val) | set(y_test))\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(class_labels))\n",
    "\n",
    "ax.bar(index, [train_counts[c] for c in class_labels], bar_width, label='Train')\n",
    "ax.bar(index + bar_width, [val_counts[c] for c in class_labels], bar_width, label='Validation')\n",
    "ax.bar(index + 2 * bar_width, [test_counts[c] for c in class_labels], bar_width, label='Test')\n",
    "\n",
    "ax.set_xlabel('Class Label')\n",
    "ax.set_ylabel('Number of Images')\n",
    "ax.set_title('Number of Images per Class')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(class_labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COUNT = 4000\n",
    "\n",
    "# Count the number of samples per class in training set\n",
    "train_counts = Counter(y_train)\n",
    "\n",
    "# Data augmentation for training set\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((384, 384), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Match EfficientNet normalization\n",
    "])\n",
    "\n",
    "# **No augmentation for validation and test sets**\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((384, 384), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Balance dataset by removing excess images and augmenting underrepresented classes\n",
    "balanced_x_train = []\n",
    "balanced_y_train = []\n",
    "\n",
    "for label in train_counts:\n",
    "    indices = [i for i, y in enumerate(y_train) if y == label]\n",
    "    if train_counts[label] > TARGET_COUNT:\n",
    "        # Randomly select TARGET_COUNT images\n",
    "        selected_indices = random.sample(indices, TARGET_COUNT)\n",
    "    else:\n",
    "        # Keep all images and perform augmentation to reach TARGET_COUNT\n",
    "        selected_indices = indices.copy()\n",
    "        while len(selected_indices) < TARGET_COUNT:\n",
    "            selected_indices.append(random.choice(indices))\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        balanced_x_train.append(x_train[idx])\n",
    "        balanced_y_train.append(y_train[idx])\n",
    "\n",
    "# Convert balanced dataset to numpy arrays\n",
    "balanced_x_train = np.array(balanced_x_train)\n",
    "balanced_y_train = np.array(balanced_y_train)\n",
    "\n",
    "# Define dataset class\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].astype(np.uint8)\n",
    "        label = int(self.labels[idx])\n",
    "        return self.transform(image), label\n",
    "\n",
    "# Create datasets with appropriate transforms\n",
    "datasets = {\n",
    "    'train': FERDataset(balanced_x_train, balanced_y_train, transform=train_transforms),\n",
    "    'val': FERDataset(x_val, y_val, transform=val_test_transforms),  # No augmentation\n",
    "    'test': FERDataset(x_test, y_test, transform=val_test_transforms)  # No augmentation\n",
    "}\n",
    "\n",
    "# Get the number of unique classes in the dataset\n",
    "num_classes = len(np.unique(np.concatenate([y_train, y_val, y_test])))\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets[x], batch_size=batch_size, shuffle=(x == 'train'), num_workers=4)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "# Count final dataset sizes\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "print(f\"Final dataset sizes: {dataset_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028be8f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bd32c",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "======================\n",
    "\n",
    "Let\\'s visualize a few training images so as to understand the data\n",
    "augmentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3074be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_images(dataloader, num_images=6):\n",
    "    images_shown = 0\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(num_images):\n",
    "            image = images[i].permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "            axes[i].imshow(image, cmap='gray')\n",
    "            axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "            axes[i].axis('off')\n",
    "            images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                plt.show()\n",
    "                return\n",
    "            \n",
    "# Show sample images\n",
    "show_sample_images(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbae0f",
   "metadata": {},
   "source": [
    "Training the model\n",
    "==================\n",
    "\n",
    "Now, let\\'s write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-   Scheduling the learning rate\n",
    "-   Saving the best model\n",
    "\n",
    "In the following, parameter `scheduler` is an LR scheduler object from\n",
    "`torch.optim.lr_scheduler`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1a57d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Create models directory\n",
    "    model_dir = \"models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    best_model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_accuracies.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_accuracies.append(epoch_acc.item())\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                patience_counter = 0  # Reset early stopping counter\n",
    "            elif phase == 'val':\n",
    "                patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    \n",
    "    # Plot training results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training & Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(val_accuracies, label='Val Acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488661e",
   "metadata": {},
   "source": [
    "Visualizing the model predictions\n",
    "=================================\n",
    "\n",
    "Generic function to display predictions for a few images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb603673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unnormalize and show an image\n",
    "def imshow(img):\n",
    "    \"\"\"Display a tensor image (Grayscale or RGB)\"\"\"\n",
    "    img = img.numpy().transpose((1, 2, 0))  # Convert from Tensor format (C, H, W) to (H, W, C)\n",
    "    img = img * 0.5 + 0.5  # Unnormalize (assuming Normalize([0.5], [0.5]))\n",
    "    \n",
    "    if img.shape[-1] == 1:  # If the image is grayscale, remove the last dimension\n",
    "        img = img.squeeze(-1)\n",
    "    \n",
    "    plt.imshow(img, cmap=\"gray\" if len(img.shape) == 2 else None)  # Use 'gray' colormap if grayscale\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Function to visualize model predictions\n",
    "def visualize_model(model, num_images=6):\n",
    "    \"\"\"Visualizes model predictions on the validation set\"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(10, num_images * 2))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot((num_images + 1) // 2, 2, images_so_far)\n",
    "                ax.axis(\"off\")\n",
    "                ax.set_title(f'Predicted: {preds[j].item()} | True: {labels[j].item()}')\n",
    "                \n",
    "                imshow(inputs.cpu().data[j])  # Show image\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c114427",
   "metadata": {},
   "source": [
    "Finetuning the ConvNet\n",
    "======================\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49381077",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load and modify the model\n",
    "model_ft = models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Freeze entire model first\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze classifier parameters\n",
    "for param in model_ft.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Define loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "# Step 4: Set up optimizer (AdamW is better for weight decay handling)\n",
    "optimizer_ft = optim.AdamW(model_ft.classifier.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Step 5: One-cycle learning rate scheduler (more stable than cosine)\n",
    "scheduler = OneCycleLR(optimizer_ft, max_lr=1e-3, \n",
    "                        steps_per_epoch=len(dataloaders['train']), \n",
    "                        epochs=num_epochs, \n",
    "                        pct_start=0.1)  # Warm-up for 10% of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede840d",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "==================\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less\n",
    "than a minute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run training\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, scheduler, num_epochs=num_epochs, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef943ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, num_classes, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []  # Store probability scores for AUC calculation\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # Forward pass\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "            _, preds = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())  # Store probabilities\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Compute classification report (Precision, Recall, F1-score)\n",
    "    class_report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "    # Compute Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Compute AUC (for multi-class classification using One-vs-Rest)\n",
    "    y_true_bin = np.eye(num_classes)[y_true]  # Convert to one-hot encoding\n",
    "    auc_score = roc_auc_score(y_true_bin, np.array(y_prob), multi_class=\"ovr\")\n",
    "\n",
    "    return cm, accuracy, auc_score, class_report\n",
    "\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_labels, normalize=False):\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # Normalize by row\n",
    "    \n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add text annotations\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\", \n",
    "                     color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "    plt.xticks(np.arange(len(class_labels)), class_labels, rotation=45)\n",
    "    plt.yticks(np.arange(len(class_labels)), class_labels)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"Actual Label\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9855775",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "cm, accuracy, auc_score, class_report = evaluate_model(model_ft, dataloaders['test'], num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, class_labels=[f\"Class {i}\" for i in range(num_classes)], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46182d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475709f",
   "metadata": {},
   "source": [
    "Inference on test dataset\n",
    "==========================\n",
    "\n",
    "Use the trained model to make predictions on test dataset and visualize\n",
    "the predicted class labels along with the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efdbaa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the number of classes (7 in your case)\n",
    "num_classes = 7\n",
    "\n",
    "# Initialize the EfficientNet-B0 model\n",
    "model_ft = models.efficientnet_b0(weights=None)  # No pre-trained weights\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Move model to device\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "model_path = \"models/best_model_0.0001.pth\"  # Update this path if your model is saved elsewhere\n",
    "model_ft.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model_ft.eval()\n",
    "\n",
    "print(\"Model loaded successfully and ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f5ada",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "cm, accuracy, auc_score, class_report = evaluate_model(model_ft, dataloaders['test'], num_classes=num_classes, device=\"cuda\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, class_labels=[f\"Class {i}\" for i in range(num_classes)], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb8157",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "\n",
    "cm = np.array([\n",
    "    [468,  29, 121,  84, 154,  36, 102],\n",
    "    [  8,  33,   5,   2,   6,   2,   0],\n",
    "    [ 72,  12, 328,  59, 134,  74,  81],\n",
    "    [ 99,  10,  89, 1413, 125,  65, 154],\n",
    "    [123,  14, 181,  69, 508,  17, 132],\n",
    "    [ 36,   4, 130,  37,  25, 579,  40],\n",
    "    [163,   1, 163, 147, 284,  54, 706]\n",
    "])\n",
    "\n",
    "\n",
    "num_classes = cm.shape[0]\n",
    "class_labels = [f\"Class {i}\" for i in range(num_classes)]  # Create class names\n",
    "\n",
    "# Compute y_true and y_pred from confusion matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for actual in range(num_classes):\n",
    "    for predicted in range(num_classes):\n",
    "        y_true.extend([actual] * cm[actual, predicted])  # Repeat actual class label\n",
    "        y_pred.extend([predicted] * cm[actual, predicted])  # Repeat predicted class label\n",
    "\n",
    "# Compute classification metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "class_report = classification_report(y_true, y_pred, target_names=class_labels, digits=4)\n",
    "\n",
    "# Compute AUC score (convert y_true to one-hot encoding)\n",
    "y_true_bin = np.eye(num_classes)[y_true]  # One-hot encoding\n",
    "y_pred_bin = np.eye(num_classes)[y_pred]  # One-hot predictions\n",
    "auc_score = roc_auc_score(y_true_bin, y_pred_bin, multi_class=\"ovr\")\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_labels, normalize=False):\n",
    "    plt.figure(figsize=(9, 8))\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # Normalize by row\n",
    "    \n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm[i])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\", \n",
    "                     color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "    plt.xticks(np.arange(len(class_labels)), class_labels, rotation=45)\n",
    "    plt.yticks(np.arange(len(class_labels)), class_labels)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"Actual Label\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Plot confusion matrix (normalized)\n",
    "plot_confusion_matrix(cm, class_labels, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dl_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
